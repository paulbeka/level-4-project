% REMEMBER: You must not plagiarise anything in your report. Be extremely careful.

\documentclass{l4proj}
\usepackage{algorithm2e}
%
% put any additional packages here
%

\begin{document}

%==============================================================================
%% METADATA
\title{Accelerating Spaceship Search Using Deep Learning in John Conway's Game of Life}
\author{Paul Bekaert}
\date{October 7, 2022}

\maketitle

%==============================================================================
%% ABSTRACT
\begin{abstract}
    \vskip 0.5em
    ``John Conway's game of life is a widely known cellular automaton which gives rise to interesting structures. One of these structures are spaceships, which translate themselves with a constant speed in one direction. Conventional spaceship search algorithm in the game of life tend to be slow due to the discrete nature of the task, and the number of possible cell combinations. In this paper, we investigate the possibility of speeding up spaceship search by using a neural network to predict cells that are in a ship. The search is implemented in an A* type fashion, with one network predicting the leaf nodes, and the other implementing a heuristic function. This is a difficult task as the game of life is inherently deterministic, and training a network for this problem would be an interesting development in finding patterns in other cellular automata. It was found that the search method implemented has difficulty converging onto a solution with spaceships that have not been used as training data, most likely due to a lack of enough spaceship data. However, the heuristic function worked surprisingly well in predicting the distance to a potential spaceship.''
\end{abstract}

%==============================================================================

% EDUCATION REUSE CONSENT FORM
% If you consent to your project being shown to future students for educational purposes
% then insert your name and the date below to  sign the education use form that appears in the front of the document. 
% You must explicitly give consent if you wish to do so.
% If you sign, your project may be included in the Hall of Fame if it scores particularly highly.
%
% Please note that you are under no obligation to sign 
% this declaration, but doing so would help future students.
%
\def\consentname {Paul Bekaert} % your full name
\def\consentdate {7 October 2022} % the date you agree
%
\educationalconsent


%==============================================================================
\tableofcontents

%==============================================================================
%% Notes on formatting
%==============================================================================
% The first page, abstract and table of contents are numbered using Roman numerals and are not
% included in the page count. 
%
% From now on pages are numbered
% using Arabic numerals. Therefore, immediately after the first call to \chapter we need the call
% \pagenumbering{arabic} and this should be called once only in the document. 
%
% Do not alter the bibliography style.
%
% The first Chapter should then be on page 1. You are allowed 40 pages for a 40 credit project and 30 pages for a 
% 20 credit report. This includes everything numbered in Arabic numerals (excluding front matter) up
% to but excluding the appendices and bibliography.
%
% You must not alter text size (it is currently 10pt) or alter margins or spacing.
%
%
%==================================================================================================================================
%
% IMPORTANT
% The chapter headings here are **suggestions**. You don't have to follow this model if
% it doesn't fit your project. Every project should have an introduction and conclusion,
% however. 
%
%==================================================================================================================================
\chapter{Introduction}

% reset page numbering. Don't remove this!
\pagenumbering{arabic} 

\section{Motivation}

"The Game of Life" (GoL) has often been seen as a toy project. It is idealistic in its representation, as it is fully observable, episodic and deterministic. However, its simple rules give rise to complex structures that are not easy to find. Those structures can be arbitrarily large, and looking for ships above a width and height of $100 \times 100$ is close to unfeasible with current methods. In general, conventional graph search methods adapted to the task are are used to find said structures. \citep{list_of_search_algorithms}. There is still a lot of room for improvement for these algorithms, and optimizing the search is still an open issue.

The concept of using deep learning to find structures in cellular automata has not yet been explored. With the advent and rise of neural networks, previously thought to be impossible problems have been unlocked, either by solving them directly or speeding up existing algorithms. Since this is a difficult search problem, it stands to reason that solving it will potentially give new insights into how to solve similar problems in cellular automata.


% MAKE THE AIMS MORE CLEAR
\section{Aims}

In this paper, we will be trying to find interesting structures in the Game of Life. Our particular interest will be in oscillating objects that move a set amount of space, so-called "spaceships". The main goal will be to test and see if neural networks can speed up the search, and how different deep learning techniques fare against each other and other conventional search methods. The expectation is that the network will greatly decrease the time it takes to find novel structures or structures already classified as spaceships.

% CHECK THIS 30 VALUE
This search algorithm is especially challenging to implement due to the aforementioned deterministic nature of the problem. There are $2^{w * h}$ possible structures in a given grid of width and height $w$ and $h$ respectively, from which only $\sim{30}$ structures have been found that can be used as training data. Although there are an infinite number of them given an infinite grid, they are tough to find. The program also bases the functionality of the algorithm on a single hypothesis that is tested in this paper, which makes the problem all the more difficult. 

%==================================================================================================================================

\chapter{Background}

\section{The game of life}
% ========

\subsection{Rules}

"The Game of Life" is a zero-player game (a simulation of sorts) invented by John Conway in 1970 which describes a cellular automata (CA) with a set of rules. A cellular automata is a simulation of cells evolving every time step, which are represented in a matrix of size $n\times m$. Every time step, the cells are modified using a set of predefined rules. In John Conway's Game of Life (GoL), a cell is either dead or alive, represented as a $0$ or a $1$ respectively. The neighbourhood of the cell is defined as Moore's neighbourhood, which is the 8 cells adjacent to the cell, diagonally and orthogonally. It can also be thought of as a $3\times 3$ matrix where the subject cell is placed in the middle. The number of neighbours the cell has is the number of live cells that are present in the cell's Moore neighbourhood, $x$. We can then define the rules of the CA described in Life:

\begin{itemize}
    \item A dead cell turns into a living cell if $n = 3$
    \item A dead cell stays dead if $x < 3$ or $x > 3$
    \item A living cell stays alive if $x = 2$ or $x = 3$
    \item A living cell dies if $x < 2$, due to underpopulation
    \item A living cell dies if $x > 3$, due to overcrowding
\end{itemize}

A state at $t+1$ is entirely dependant on the current state at $t$ and is calculated using the rules above. The game can go on indefinitely, but usually reaches a state in which cell structure does not change in any significant way. For example, all the cells could die, creating an empty board. More likely however, is that the resulting state will be populated with still-lifes, oscillators, and sometimes spaceships, which are defined below.

\begin{figure}[h]
\centering
\includegraphics[width=0.4\linewidth]{dissertation/images/diagrams/moores_neighbourhood.png}
\caption{Moore's Neighbourhood. This is the space of interest for any given cell (grey squares). The number of neighbours a cell has is the number of alive cells within this neighbourhood.}
\label{fig:subim1}

\end{figure}

\subsection{Still lives}

A still life is a structure that does not move or change shape from generation to generation. They remain static (do not move around the board or in shape), unless outside cells interact with it. Still lives are by far the most common structures in the GoL, and they are easy to find, as they have the same shape for $t$ and $t+1$. Here are some examples of still lives:

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/still_life_1.png} 
    \caption{The Block} %SHOULD I GET RID OF THIS ONE OR RE-DRAW IT SOMEHOW?
    \label{fig:subim1}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/still_life_2.png} 
    \caption{The Tub}
    \label{fig:subim1}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/still_life_3.png} 
    \caption{The Boat}
    \label{fig:subim1}
\end{subfigure}

\caption{Examples of still lives}
\end{figure}

\subsection{Oscillators}

These are structures that change shape, but return to the same state every $p$ generations. They are  harder to detect, as it is impossible to know how many generations it will take for the structure to repeat. An oscillator will stay in the same position after it has oscillated, and will keep oscillating as long as it is undisturbed by other cells and the program keeps running. Here are some examples of oscillators:

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/toad_transition.png} 
    \caption{The Toad}
    \label{fig:subim1}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/blinker_transition.png} 
    \caption{The Blinker}
    \label{fig:subim1}
\end{subfigure}

\caption{Examples of oscillators and their different iterations}
\end{figure}

\subsection{Spaceships}

% TALK MORE ABOUT THEM
Spaceships are the main focus of this paper, and are the hardest structures to detect. They are similar to oscillators in that they repeat their state every $p$ generations. However, they also move a certain distance since their last oscillation. If the state space they are in is unbounded, then they will move forever without changing direction.

The speed of a spaceship is determined in terms of the speed of light of GoL, $c$. This $c$ is defined as 1 cell per second, as it is theoretically the quickest information could hope to propagate given the rules of Life. The ship can move diagonally, orthogonally, or knightwise, which is when a ship moves in an oblique direction. A spaceship with a period $p$, which is moving $n$ cells in a particular direction is said to have a speed $nc/p$. A ship moving $n = 2$ cells left and with a period $p = 5$ will have a speed of $2c/5$. For a ship moving knightwise $n$ cells either left or right, and $m$ cells either up or down, will have a speed denoted as $(m, n)c/p$. These speeds can be simplified, for example a spaceship moving at speed $2c/4$ can be written as $c/2$.

\begin{figure}[h]
\centering
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/glider.png} 
    \caption{The glider}
    \label{fig:subim1}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{dissertation/images/gol_structures/LWSS.png} 
    \caption{The LWSS}
    \label{fig:subim1}
\end{subfigure}

\caption{Examples of spaceships}
\end{figure}

There are 2 principle ways of classifying spaceships: engineered and elementary ships. Elementary spaceships are those which can be found naturally in the GoL via searching a random soup, which is starting with a random grid of cells and it evolving into a spaceship They are also classified as ships that have been found by a search algorithm. Engineered spaceships are those created by people using small interacting parts to assemble a ship as a whole. There are an infinite amount of spaceships in the GoL, however few elementary spaceships have been found, whilst some engineered spaceships have been found that can be extended forever. In this paper, a mix of engineered and elementary spaceships are used as test data, and the search looks for both equally.

% ========

\section{Different ways to find spaceships}

The problem we're trying to solve is to find new spaceships in general, however the focus are on "interesting" ships, which consist of mostly elementary ships, and some engineered ones. These are, as explained above, structures that repeat inside of a game of life grid, but also move a certain amount of space. This is a widely known toy problem, however it is complex and brute force is out of the question. In a given $n \times m$ grid, there are $2^{n \times m}$ possible combinations. For example, a glider, which takes at least a $3x3$ grid to be represented, would be found by searching $2^{9}$ grids. Brute force becomes unfeasible after approximately $n > 6, m > 6$. This algorithm tends not to have much use, but it has found a comprehensive list of all still-lives, oscillators, and spaceships within a small rectangle.

A better approach is representing the board as a graph. By representing each cell as a path- a path where the cell is either alive or a path where the cell is dead- a tree search method can be used. This is the method used in most algorithms today, by trying to optimize which cell should be placed next. Some combinations of cells should not be placed together as the result would be incompatible with a spaceship, and therefore the algorithm can eliminate entire sub-trees from the search space.

\section{Existing Search Methods}

There are not many research papers on the subjects, but in Searching for Spaceships \citep{searching_for_spaceships}, a de Bruijn graph is used to represent the cells. The algorithm - "gfind" - only works on one side of the ship, and assumes the other to be symmetrical. A ship is then constructed by applying the GoL rules to rows of the ship, and placing the formed cell in front of the ship in the direction it will move. To visualize this, imagine the grid follows the ship as it is moving, so that the ship looks like it is simply oscillating. A future oscillation can therefore be predicted by taking the evolution of the spaceship for every row of 3, and applying it $p$ (the speed of the ship) cells above the evolution, as it would reach that point p next iteration. This approach has one major drawback- any spaceship that is not a "long" spaceship will not be detected. The search space also does not include asymmetrical spaceships, of which there are many.

Another well known algorithm to find spaceships or oscillators is "lifesrc" created by David Bell, uses a depth first backtracking search. The grid is first set up with a few known cells, set by the user. The rest of the cells are classed as "unknown". When the algorithm starts running, a decision is made on whether a cell should be alive or not, and the program will check forward and backward if there are any oscillating patterns of period $p$ set by the user. If nothing is found, the search continues, using the decided cell. If it is found later on that a cell placement in a particular cell is impossible, or that there are no oscillators in a particular configuration, then the algorithm will backtrack to the latest cell it decided on randomly. This is essentially a depth first search, however it discards certain sub-trees by eliminating ones that do not follow the Life rules (for example, checking if every cell is alive in a $4 \times 4$ grid would be redundant, since almost all cells in that grid would die in the next iteration). 

The most efficient algorithm used to find spaceships today is dubbed the "ikpx2" algorithm, which was created by Adam P. Goucher. It was inspired by gfind, which searches De Bruijn graphs representing the different parts of a spaceship. However, ikpx reduces the spaceship search problem into a set of SAT constraints, which can then be used on an SAT solver. The problem is reduced to by using quotient latices to represent cell structure, and cell combinations which cannot exist together are false, whilst possible patterns are set to true. The solver used in question is the "iglucose" \citep{sat_2018} SAT solver and sped up the search considerably, as a lot of research has gone into accelerating SAT solvers. A notable find by the ikpx2 algorith was the "knightship": the first oblique spaceship found, or in other words, a spaceships that does not move diagonally nor orthogonally.

\section{Deep Learning with the GoL in General}

There are a few research papers written on neural networks and the game of life, with one notable one being about forward planning in the GoL \citep{game_of_life_dl_is_hard}. In this paper, they try to predict the future structure of a starting configuration. They used several 1x1 and 3x3 convolutional layers in their network, activated by ReLU functions. Although the model was able to perfectly predict the next iteration of the game, the further the model tries to predict, the worse the result. The problem hypothesised by Springer is the "lottery ticket problem", in which the starting configuration of the model is what would allow it to converge to a correct solution. 

Apart from research done, there are many hobbyists working on combining deep learning with GoL. One of them is James McGuigan, who trained a neural network to learn the game of life after one iteration \citep{james}. He has also worked on reversing the game of life, trying to find a previous configuration using a current board state. Another notable use of deep learning and the game of life is by NeatAI, who used genetic algorithms in the game of life \citep{neatai_gol}. He used a $c$ function that calculates the overall "complexity" of the current structures in the grid. For example, a grid with random cells is not very interesting, but one that has a couple of gliders and oscillators with high periods may be of more interest. To design his $c£$ function, he took inspiration from a paper by \citep{algorithmic_specified_complexity}, which describes a process of encoding interesting objects in the game of life. It uses features of an object such as shift, repeating period, intersection between 2 or more objects, to define the properties of such an object, These properties are then bit-encoded to form a number that specifies the complexity of the object. To find the complexity of a particular state on a board, the sum of the object complexities is taken.

NeatAI took this $c$ function and applied it to a neural network which determined whether or not a cell should be alive given the input parameters $x$, $y$, population density, and bias. He then used genetic neural networks to improve his model to maximize the $c$ function. The net improved by making optimal start configurations for the model to evolve into. This is an interesting concept, as if the $c$ function were to be changed to be maximised by how far a pattern has reached from the origin, it could potentially be used to find new spaceships for example.

\section{Summary}

In this section, we've defined the game of life and its rules set by John Conway. This involved the definition of a cellular automata, the way the board evolves over time, Moore's neighbourhood, and the rules for a cell to be dead or alive. Different definitions of structures were shown, such as still lifes like the block, or oscillators like the blinker. Spaceships were defined as an interesting oscillating structure that moves across the board with a certain speed which can be denoted using the "GoL speed of light", $c$, which is the maximum speed information can propagate (1 cell per iteration). We then looked at different ways to find spaceship, namely brute force (which is computationally impossible after a certain point due to the exponential amount of possibilities) and tree search. Tree search involves representing cell changes as nodes on a tree, and searching the tree for a solution. Existing search methods were covered such as "ikpx" and "gfind". Their use of de Brujin graps- and SAT solvers for "ikpx"- was detailed, again using tree search to find structures. Finally, an overview of deep learning in the game of life was mentioned. Although there has not been much research done in this field, there have been amateurs working on it such as James McGuigan, who tries to train neural networks into learning the previous state of any given state. Furthermore, others have tried to simulate a GoL state after $k$ steps, with limited success.

%==================================================================================================================================
\chapter{Design}

\section{The Problem To Solve}

The main objective of this paper is accelerating tree search of spaceships in the game of life by using neural networks. The search method will follow an A* search pattern, wherein a scoring network will be used as a heuristic function, and a probability change network will be used to select which cells should be used as branches. This network is responsible for scoring potential cells to be changed in a given structure. The algorithm then uses threshold values to find which cells should be added as a branch to the current state. These branches are then scored by the heuristic function. The networks will be trained on spaceships only below the size of $100 \times 100$, however in theory, the network could then work for any size.

\section{The Main Assumption}

Neural networks can be good at detecting general patterns in objects. There has been a lot of debate in the GoL community about an underlying pattern to spaceships. There have been methods by the community which use "spaceship engineering" - combining multiple identified sub-parts of spaceships to make a new moving ship. However, there has yet to be a formalized equation or pattern found to help fast-track the search of such ships. To use a neural network for this problem, the approach taken in this paper revolves around the assumption that spaceships have an underlying pattern which is detectable to a neural network. Although there are not many spaceships, data expansion methods are used to gather more data, and convolutional techniques are used to train the network. This assumption is also used in the scoring network, as only ships that have been trained on will have a high score, implying that there is also some type of general pattern. 


\section{The Search Algorithm}

The algorithm is a standard A* tree search, but uses two neural networks to help accelerate it. The first network is trained to generate branches for any given node, and the second is used as a heuristic function. Every node in the tree contains a grid, which is the state of a GoL world, and a number of times it has been visited. The branches of the node represent a change of 1 cell from that node. For example, a cell that has been brought to life, or a cell that has been killed. The first network outputs a probability change grid for every cell in said grid. This probability change is how much the network believes the cell should change. If the probability is near 0, then the cell should stay unchanged. However the closer to -1 or 1 the probability change value is, the more probable that it must be changed. Branches of the current node are based off this probability change output, which is first filtered via thresholds, and values with the biggest positive and negative magnitudes are used as branches. The top $n$ cells with the greatest positive probability change, and top $n$ cells with the lowest negative probability change, are used as branches to create $2n$ nodes. These are presented as actions to the tree search. Then, the algorithm scores these new grids using the scoring neural network. This is used as a heuristic function to find the grid which is most likely to converge to a spaceship. The heuristic function is combined with the number of times a node is visited, which allows search of the entire tree structure and prevents loops. If the score is better than the highest found score, it is added to a list of top scores. Once the max depth of the tree search is reached, a subset of the top scores list is returned. Those grids are checked for spaceships, and an aggregation function is used to find cells that appear in every grid. This aggregated grid is then fed back to the tree search as an initial node. Iterative deepening is used, in the sense that the max\_depth will increase as the number of iterations increases. This is done to prevent a loop wherein the output of the tree search results in the same input for the next tree search. The number of iterations can be arbitrary, with more iterations leading to more chance of finding a spaceship.

\section{The Networks}

There are two main networks that this algorithm will use to guide the search:

\begin{itemize}
    \item The probability network: used to find which cells should be modified
    \item The scoring network: used as a heuristic function
\end{itemize}

The probability network uses a fully convolutional network without pooling layers. Swish activation functions are used between each convolution, and will output a convolution that retains the size of the input. Input of the network consists of a configuration of cells with values ranging from 0 to 1, each representing a probability of a cell being present. The output is then given as a change of probability of the input.

The scoring network also uses a series of convolutions, but is then followed by an average pooling layer, and finally a fully connected layer to predict a final score between 0 and 1. Scoring of this network is used as a heuristic to find how far a given solution is from converging towards a spaceship; the idea being that this problem can be turned into an A* type of search.

\section{Data used to train the network}

For a ship to qualify as a training item in the network, it needed to be under $100 \times 100$ in width and height. This is done for data processing reasons: creating and augmenting the data at greater sizes than this will be significantly slower. The ships selected were all different in structure. That is, any spaceship was independent; for example, an engineered spaceship that is infinitely extendable would only appear in the dataset in its minimum size (minimum working form). A majority of the spaceships used in the dataset were elementary ships for this reason.

One major problem with training the networks is the lack of enough spaceship data. There are not many spaceships which follow different patterns known in the game of life. This leads to the networks learning a specific ship pattern, instead of a general structure for these ships. In order to mitigate this problem, data augmentation was performed. A ship is evolved through all of its different shapes until reaching its original structure. This gives $p$ more grids to train with, where $p$ is the period of the ship this method is being applied to. Once that step is complete, further augmentation can be done by rotating the ship in all 4 directions. Since the GoL rules are the same in every direction, this will not break the spaceship. Using this method, it was possible to enlarge a dataset of $\sim 30$ ships into $\sim 900$ ships.

To get the necessary data to train the actual networks, input-target pairs were needed. These were obtained by removing a number of cells from a spaceship, and adding a number of cells to other parts of the ship that weren't there originally. This had the effect of creating a linear path of reconstruction given a starting grid of cells. The number of missing and added cells was increased linearly, and the number of added cells was also randomized to add some noise, preventing the neural network from learning to base a ship on the number of cells alive. A solution matrix can then be constructed by taking the difference between the actual ship and the deconstructed grid. The probability network used the deconstructed grid as input, and the solution grid as an output, since its target is the solution matrix. As for the scoring network, an MSE (Mean Squared Error) function can be used to evaluate the MSE between the original ship and the deconstructed version. This score can then be used as a training value for the network. 

\section{Summary}

The design section begins with an explanation of the main features of the algorithm, including a short description of tree search. Nodes are used to represent a particular board, and the networks are applied to these boards. The probability system was also explained, wherein the cell probabilities are used to chose which cells will be switched next. The probability change network was detailed, talking about how candidate cells are extracted from this probability network, and then scored by the scoring network. The main assumption for this to work is addressed, that being that an underlying general pattern must exist in GoL spaceships. Finally, data extraction: which spaceships were included, how to extract more spaceship data from any singular ship, and the training data that can be created with the deconstruction method. The deconstruction method was talked about, as it was used to train the networks used in the algorithm. The data is a collection of "solution pairs", which is a tuple containing a noisy spaceship and a solution matrix. The scoring network also uses this tuple, but finds the MSE between the two grids in the solution pair as its target output.


%==================================================================================================================================
\chapter{Implementation}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{dissertation/images/diagrams/general_structure.jpg} 
\caption{General structure of the implementation of the search algorithm. This includes data, training models, the search itself, and tools.}
\label{fig:subim1}
\end{figure}

\section{Software Engineering Practices}

Identifying what needed to be done in the project was key to advancing in a timely manner. To achieve this, I kept an organised file which contained the tasks and objectives of the project, and a set list of things I needed to do within a certain week. In addition to this, a waterfall project development method was employed, which suited the project well as it was a clear incremental step-based approach: first design a network to predict good cell probability values, then create a scoring network, and then assemble everything. Each step of the process had to be tested individually and as a whole. Using a daily planner, I would also plan out the objectives of my day, including things that needed doing in the project. I also kept a sheet logging the hours I put in the project, and what happened during those hours. GitHub was used as version control for the code, which was useful as it is free and widely used, but also allowed my supervisor to access my code easily.

\section {Unsuccessful Attempts}

In this section, alternative initial methods to find spaceships that were initially tried are explained. These methods did not work out for a variety of reasons, but helped pave the way to the current search algorithm. 

\subsection{Ship Probability}

My first try to solve this problem revolved over giving structures a "probability" as to how close they are to being a spaceship. The idea was to teach a network the probability of a structure being a ship. A series of convolutions and pooling was used, followed by an adaptive convolutional layer which was then fed to a fully connected network. Given an input, this network would produce a probability of the input being a spaceship. This technique did not work for several reasons: The pooling lost information about the structure, the fully connected network was not able to properly converge, and the output was a softmax which was unreliable as a probability. Furthermore, the training data used on this network was not as complete as the training data used in future trials. Instead of the deconstruction of ships as mentioned in section 4.3, the data it trained on was either a ship or a random collection of cells. There are multiple problem with this, but the main issue would be that a ship would have abundant amounts of dead cells around it, which made them easy to detect by the network. To counter this problem, different density ratios were used, along with reducing the size of the random noise to be that of the size of a spaceship. However, this did little to improve the network, most likely due to its fully connected nature, which failed to converge due to having to learn locality from scratch.

This probability prediction neural network was fed to a tree search which worked by flipping cells off and on and checking if the probability of the structure being a spaceship increased. This did not work very well, partially because the network did not produce good results, but also because the fully connected layer meant that changing a single cell did not change the final output significantly. Large changes in the structure did yield better results, since a greater change in the input would produce a change to the fully connected layer, but was ultimately not useful for finding new ships. 

This initial network may sound familiar: the scoring network used in the search algorithm. However, there is one key difference between the two. While the ship probability algorithm tried to find the \emph{probability} of a structure being a ship, the scoring model tries to model the \emph{positive MSE loss} of a structure to a spaceship. The positive MSE loss is essentially the same as MSE loss: however the higher the value the better the score. This scoring function is more reliable than a probability, as it best represents how "close" the ship is to being complete, which is what the search algorithm converges towards.

\subsection {Stochastic Ship Cell Probability}

This second method attempted was similar to the method being used now. As mentioned, the value of every cell is represented as the probability of a cell being alive. This originally came from the idea that perhaps a stochastic version of the search algorithm could be used: activate cells based on the probability of them being alive, and then check if it is a spaceship. Repeat this until the probabilities are polarised to one side or the other. This did not work for a major reason: since the problem is deterministic, one small error in a cell can lead to the difference between a spaceship or not. With a stochastic search, even if the probabilities are close to being correct, the error in probability can quickly add up and reduce the chance of a spaceship being generated significantly. In addition to this, the network training did not fit well enough to be used in a probabilistic manner. Since the model was trained on 1s and 0s, applying the network output on itself would give the same exact output from the last iteration, which meant there was no change of input for the model. Furthermore, since there are on average a large amount of dead cells in any given spaceship, the model was trained to decrease probabilities everywhere. This means that after a few iterations, the probability of any cell was 0.
%This could have worked if more data was used, but the dataset used for the current search algorithm was already huge?

\section{Challenges faced}

Finding spaceships has been a challenge many in the GoL community have attempted, mostly using algorithmic methods and logical tree search programs. However, there is close to no research done on deep learning in the game of life, and no one has tried to find spaceships using it before. This meant there was little work to go off of, and a lot of assumptions had to be taken. Furthermore, since there is an explosion of possible paths when representing the problem as a tree, any conventional algorithm is slow in navigating the search space. Even with acceleration of the search using these networks, searching such a problem is slow. One way to mitigate this, as seen later in the paper, is to limit the amount of possible branches in any given state. 

Another issue was overfitting. It is very hard to get good results, and any that are found are most likely due to the network learning the spaceship structures instead of a general pattern, which is due to low diversity in spaceships. Even after data augmentation, the underlying spaceship pattern remains similar, and therefore may not be diverse enough. The original amount of spaceships used was $\sim 30$, which is a very low number. 

The amount of data available for training was problematic. As mentioned previously in section 3.5, there were not many spaceships to work with. Even if there exists a general pattern to spaceships as indicated in section 3.2, the lack of data may mean that this general pattern is impossible to identify due to the shortage of different types of ships. With more spaceships, a solution might be easier to converge on. However, using augmentation, a lot of extra data was created, even if still the same spaceship. The amount of augmented data used by this network was huge. Coupled with the fact that several convolutions are needed, training the network took days. Due to the limited time available, testing new networks was difficult, as training had to take place on another computer with a better GPU. This meant that even small changes to convolution size or other such parameters would take days to get results, and slowed down the testing process significantly. Hyper parameters might have been tuned to a better degree had there been a better way to train the networks.


\section{Probability Search}

\subsection{Choice of Technologies}

This project is the first time I ever used deep learning to complete a project, which meant I needed a quick and easy introduction into deep learning. The most obvious choice as someone who is familiar with Python and has never done any sort of machine learning was PyTorch. It allows for quick assembly of a neural network in python, and can be easily tested. Numpy was essential to allow rapid evaluation of GoL states. Since the code involves a lot of transformations of matrices, Numpy was perfect for quick and easy computation. Pandas and matplotlib were used heavily for the evaluation of my search method. Finally, to create a dynamic GoL testing environment, Pygame was used to represent the grid, iterate the matrix forwards/backwards, and generally see the results of search operations. Pygame was chosen for its simplicity when it comes to setting up a user interface, and even though it is slow, it was only used for data representation which made it ideal. If the matrix did not need to be interacted with, matplotlib was used. 

\subsection{Data and Data Augmentation}

In this paper, the selection of spaceships was important. Those selected were small (less than $100 \times 100$ in size), had any speed, and were usually elementary spaceships, but there are were a few engineered ships. The engineered spaceships selected were only those in their base form, as they can be infinitely extended. These ships are classified as "interesting" by the community, and are stored in a database called "new-gliders.db" \citep{newgliders_db}. The resulting dataset is quite small in size, fielding 31 spaceships in total. This is not ideal, as the number of ships should be as big as possible in order to get an idea of a ship pattern that will work well. To mitigate this lack of data, the ships were rotated to face all 4 directions, giving 124 different structures. Next, the ships were evolved in each direction, and all their period transitions were recorded. This expanded the dataset to around 1000 items.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{dissertation/images/diagrams/increasing_ship_data.png} 
\caption{Increasing dataset size by rotating ships in all 4 directions and iterating over all periods. Here you can see the Glider, which went from only 1 item in the dataset to 16.}
\label{fig:subim1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{dissertation/images/diagrams/data_augmentation.jpg} 
\caption{A general view of the ratio deconstruction method. The ship has some cells removed, some added, and a solution matrix is constructed subtracting the deconstructed data from the original ship.}
\label{fig:subim1}
\end{figure}

From the expanded dataset, more data can be created. The problem now is to create data that will be used to train our neural networks. Since the problem we are trying to solve is a change in probability given an input of living and dead cells, one approach is to show the network the solution matrix of a given configuration (Fig 3.2). This involves a deconstruction-reconstruction method. The method devised in this program was named $ratioDeconstruct()$, which took in a spaceship, and a ratio of the ship which should be deconstructed (0 being no deconstruction and 1 being deconstruction of the whole ship). A deconstruction ratio of 1 is recommended, as it allows the network to be exposed to entire ships as a solution. A graphical representation of this deconstruction method is shown in Figure 4.4. The ratio deconstruct method works as follows:

\begin{enumerate}
    \item Starting with a starting configuration, $x$, set a ratio of deconstruction $r$ and a number of configurations per deconstruction item, $n$. This $n$ value is the number of configurations generated for any number of missing cells in the ship.
    \item Find the maximum number of cells to be removed from the configuration $x$ by $n\_cells\_removed = alive(x) \times r$.
    \item Loop for $i$ in the range of $n\_cells\_removed$ (i.e, start at $i=1$ and end at $i = n\_cells\_removed$. In a nested for loop, generate $n$ items as follows: Remove $i$ alive cells from the ship, which is the deconstruction part. Once deconstructed, generate a random number of alive cells calculated from a normal distribution centered on $i$, and add them to the original dead space of the ship. These are dummy cells, noise, added to the structure.
    \item Once the generated item has been created, $y$, create a solution matrix $s$ by $s = x - y$. A tuple $(y, s)$ is created, where $y$ will be the input of the matrix, and $s$ will be the target. This was dubbed a "solution pair".
    \item The dataset is then shuffled and batched to then be sent to the network trainer.
\end{enumerate}

This method was used to generate the data used by both the probability change network, but also by the scoring network. However, the scoring network used an MSE (Mean Squared Error) calculator instead of the solution matrix $s$. This score is calculated by $MSE(x, y)$. This generates a scoring value for the network to train on. The MSE was used as it is a good measure of how far a ship is from completion. Larger errors will lead to a larger penalty, encouraging a search to make less errors. The data tuples used for the scoring algorithms are as follows: $(y, MSE(x, y))$, which is essentially a mapping of a generated noisy matrix along with a score. This MSE value is calculated using a function built into pytorch.

\begin{figure}[h!]
\centering
\includegraphics[width=1\linewidth]{dissertation/images/diagrams/data_augmentation_implementation.jpg}
\caption{Data augmentation from the HWSS. In this example, 3 sets are created for every number of cells removed. In this example, this will generate $13 \times 3 = 39$ augmented examples from 1 spaceship configuration.}
\label{fig:subim1}
\end{figure}

\subsection{Architecture of the networks}

\subsubsection{The probability network}

The probability network uses a series of convolutions and swish activation functions to find the given change of probability in a cell. Swish was used to counter the dead neuron problem, as the neural network used is quite deep, and could disregard important cells is ReLU was used. The use of the convolutions is to encourage locality. In the GoL, only the cells in Moore's neighbourhood are considered (those directly adjacent). Therefore, it follows that a convolutional network would be the best fit, as the probability of a cell being present on a spaceship would largely depend on cells close to it. However, not only $3 \times 3$ filters were used. Near the end of the network, it was found that using $5 \times 5$ filters were very effective, which could be due to larger cell patterns depending on one another to fully move a ship. In between the $3 \times 3$ and $5 \times 5$ layers, a $1 \times 1$ layer was added. The argument behind this convolution is to modify individual cells which are more or less important based on where they are. This network was trained with the aforementioned "ratio deconstruction" method in section 4.4.2.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/diagrams/probability_network_diagram.png}
\caption{Cell Probability change network}
\label{fig:subim1}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/diagrams/scoring_network_diagram.png}
\caption{Scoring network architecture}
\label{fig:subim1}
\end{figure}

\subsubsection{The Scoring Network}

The probability network is good for finding potential cell changes given an input. However, it does not always give the best cell as a candidate. In order to determine the optimal path given candidate cells, a scoring function is employed to guide the search process. The scoring network works in a similar manner to the probability network, with the exception of a average pooling layer before feeding the output into a fully connected network, which then outputs a score. The scoring network also presumes the existence of a fundamental ship structure. This differs from the original ship probability model, as the network aims to predict a preexisting function rather than a probability. The goal of the network is to score structures that are close to being a spaceship higher, and to score structures that are further from being a spaceship lower. This was done by reflecting the resultant score on the $y$ axis. The $y$ value found as the best point for reflection was $y=0.08$, which allows for the score to reach 0 on average if the structure is very far from being a ship.

Both the neural networks used an MSE loss criteria and an Adam optimizer based off torch. MSE loss was used as the criteria due to a difference of two matrices being well represented with such number. Furthermore, MSE loss discourages larger errors, which means errors that greatly damage the spaceship are avoided easily. The Adam optimizer was used as it is a generally sturdy algorithm, which has few parameters to tune. Given the complexity and amount of training time required for the problem, using Adam simplified the process and allowed for a quicker development time.

\subsection{The Searching Algorithm}

\begin{algorithm}
    \DontPrintSemicolon
    \KwData{Implementation of the search function, $search(initialInput)$, which takes in an initial input grid. This grid must contain a few initial alive cells.}
    \KwResult{A list of spaceship data, in the form $[\{period, speed, rle\_code\}]$.}
    \Begin{
        $currentNode \gets initialInput$\;
        $n\_iterations \gets 5$\;
        $n\_tree\_returns \gets 5$\;
        $max\_depth \gets 30$\;
        $spaceships\_found \gets []$\;
        $i \gets 0$\; 
        \While{$i < n\_iterations$}
        {
            $bestNodes \gets []$\;
            $visitedNodes \gets \{\}$\;
            $j \gets 0$\;
            \While{$j < max\_depth$}
            {
                $possibleActions \gets currentNode.getActions()$\;
                $currentNode.incrementVisited()$\;
                add $currentNode$ to $visitedNodes$\;
                \eIf{\texttt{possibleActions not empty}}
                {
                    $currentNode \gets max(possibleActions, key: action.getScore())$\;
                }{
                    $currentNode \gets max(visitedNodes, key: action.getScore()$\;
                }
                \tcp{If the current node has a better score than the last node which was added to the list, then append it to said list.}
                \If{$currentNode.getScore > bestNodes[-1]$}
                {
                    append $currentNode$ to bestNodes\;
                }
            }
            $candidateNodes \gets bestNodes[bestNodes.size - n\_tree\_returns:]$ \tcp{Get top nodes}
            \ForEach{$node \in candidateNodes$}
            {
                \If{$checkSpaceship(node)$}
                {
                    append $getSpaceshipData(node)$ to $spaceships\_found$\;
                }
            } 
            \tcp{Now aggregate the nodes to find common values}
            $currentNode \gets aggregateCommonCells(candidateNodes)$\;
        }
        \Return spaceships\_found
    }
\end{algorithm}

\begin{algorithm}
    \DontPrintSemicolon
    \KwData{Implementation of the $getActions()$ method used within nodes to get a list of possible children (finding candidate cells given a grid). The node itself is represented with the $self$ keyword.}
    \KwResult{A list of nodes which each have 1 cell changed.}
    \Begin{
        $possibleActions \gets []$\;
        $n\_considerations \gets 3$\;
        $probabilityGrid \gets probability\_change\_model(self.grid)$\;
        $addCells \gets list\_items\_where(probabilityGrid > upper\_bound)$\;
        $removeCells \gets list\_items\_where(probabilityGrid < lower\_bound)$\;
        \tcp{Make nodes for the cells added}
        \For{$i = 0 \to i = n\_considerations$}{#
            \tcp{Find the maximum value of change}
            $addCandidate \gets max(addCells)$\;
            $newGrid \gets self.grid$\;
            $newGrid[addCandidate.index] \gets 1$\;
            remove $addCandidate$ from $addCells$\;
            $newNode \gets Node(newGrid)$\;
            append $newNode$ to $possibleActions$\;
        }
        \tcp{Make new nodes for cells removed}
        \For{$i = 0 \to i = n\_considerations$}{
            \tcp{Find the min value, cell network wants to remove the most}
            $removeCandidate \gets min(removeCells)$\;
            $newGrid \gets self.grid$\;
            $newGrid[removeCandidate.index] \gets 0$\;
            remove $removeCandidate$ from $removeCells$\;
            $newNode \gets Node(newGrid)$\;
            append $newNode$ to $possibleActions$\;
        }
        \Return{$possibleActions$}
    }
\end{algorithm}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/diagrams/tree_diagram.jpg}
\caption{Example of tree search to find the Glider. The most promising path is followed. Notice there are not always 3 candidates- that is because sometimes the number of cells that cross threshold values are below the maximum number of candidates.}
\label{fig:subim1}
\end{figure}

The search algorithm in this paper works off a graph search, wherein different board states are represented as nodes, and each branch is a change in one item (cell), giving rise to a new board (state). This change can be turning a cell into an alive or dead one. The search is an A* approach to a tree formed by those nodes. The probability network is applied to the current state, and using fine-tuned threshold values, a select few of those cells are chosen to as branches to the current state node. The heuristic function of these nodes are calculated by using the scoring network. Once a node is visited, it is added to the "explored" list, with a visited attribute incremented. When the current state does not have any available nodes to expand into, for example if no cells in the probability change output surpass the threshold values set, then the state with the maximum score is selected from the explored list. This is the reason why the threshold values must be fine tuned: the tree search will keep moving down the tree as there will always be possible nodes to change without the threshold values. If there were always options for a node, the tree search could not go back to a better state, and would get stuck in one part of the tree forever. In addition to limiting the number of nodes via thresholds, the threshold values are a function of the the current iteration in the tree, which means the restrictions on which cell to chose increases over time. The tree iteration method is done several times, and in between, a state aggregator is used to find the alive cells in common of the top $k$ items returned by the tree search. This gives a baseline model from which the tree search can be restarted, the idea being that only important cells would have been found by the top scoring states. An iterative deepening approach is also used, as the max\_depth value is increased as the number of iterations increases. Iterating over a tree search is expensive, as it requires aggregating the states, but also checking if any of the returned states are a spaceship, which is costly.


\begin{figure}[h!]
\centering
\includegraphics[width=0.9\linewidth, height=20cm]{dissertation/images/diagrams/spaceship_tree_search.jpg}
\caption{Search method architecture}
\label{fig:subim1}
\end{figure}

\subsection{Tree Search}

The search starts with an initial node $i$, set by the user or generated by the program. This is then fed into the tree search algorithm as the initial state. The node class contains a $getActions()$ method. $getActions()$ will return a list of candidate states (nodes) for that node, based firstly on the probability change network, and secondly by the threshold values. The two threshold values are that of the removal of cells, and addition of cells. There are in total a maximum of 3 candidates for removing or adding cells, represented by the variable $n\_considerations$, and a minimum of 0 candidates if no cells pass the threshold value. This means the total number of candidate cells has a maximum of $n\_considerations \times 2$. Once the cells that satisfy the threshold value requirements are selected, new nodes are created for those changes, which are set as child nodes of the current node being analysed. Nodes have two attributes: the number of times they've been visited, and their GoL grid representing the cells. The heuristic function for any given node is calculated as follows:

\[ h(s) = \texttt{scoringNetwork(s.grid)} + \texttt{s.visited} \]
 
The node with the highest score is selected as the next node. Once the next node has been selected, it is set as the current state, it's visitation count incremented, and added to the "explored" list. If there are no candidate states available to chose from, a node will be fetched from the explored list and set as the current node. The node that is selected has its number of times visited incremented, and is re-added to the list. The tree search will then continue, until max\_depth is reached, at which point it will return the top $k$ nodes with the highest scores.

\subsection{Iterating over Tree Search}

\begin{figure}[h!]
\centering
\includegraphics[width=0.4\linewidth]{dissertation/images/diagrams/iteration_aggregator.png}
\caption{The iteration aggregator in action. As can be seen, only cells in common are kept. The result is encouraging: only 1 cell away from the Glider. In this example, tree search outputs its top 3 highest scoring states}
\label{fig:subim1}
\end{figure}

Although the tree search worked in some cases, a lot of the time the result of the tree search would be focused on one area of the tree which maximised the score, but did not find spaceships. This means that the solutions given were quite close to one another. To solve this problem, bias adjustment was needed to re-focus the search on the general aspect of the ship. To do this, the top $k$ outputs of the tree search are aggregated in a way to only keep cells which appeared in all of the outputs. This is done with an AND operation over all outputs. When the tree search gets close to the solution, it has been observed that finding the correct cell which will fix the ship is difficult. This is most likely due to the scoring function: since MSE is a squared error function, the error is exponential in nature. When the algorithm comes close to converging to a solution, the change in score is almost insignificant. This leads the tree search to accidentally change the wrong cell, and therefore get stuck in a loop where it is essentially using trial and error to get the correct cell. By cutting the tree search at an early max\_depth, the input can be re-organised to only include the core cells important to the ship, and re-input them in the tree search. 

Two major drawbacks of using this method is it may cut a solution early, and ship detection is slow. If the tree search is almost at the solution, then re-starting form the core cells may cause issues, as the program may get stuck in a loop of going down the same path, producing the same outputs, and therefore never creating a new output. A partial solution to this problem is explained in section 4.5.4, and involves turning the max\_depth parameter into a function of current iteration index. Furthermore, ship detection is a costly operation, and by increasing the number of iterations, the speed of the algorithm slows down considerably. Theoretically, the higher the number of iterations, the more likely a spaceship is found, as the program will just run for longer.

\subsection{Other approaches for choosing next state}

There were 2 other methods thought about for choosing the next state. The first was to re-apply the network output on itself for a set amount of iterations. This, in theory, would create an output that would most resemble a spaceship in terms of what the network thinks will be the spaceship.

However, a major problem with this network is that the output is very negative (cell probability changes tend to be negative), which is due to the large amount of dead cells in any given spaceship. If the network output is re-applied to itself several times, information could be lost due to cell probabilities approaching 0. This is why the branched cell-by-cell approach was selected: the probability does not converge toward 0, and the cell count can increase as well as decrease based on the output of the scoring function. Even if this problem were overcome, the network would face another issue: any input gives the same output. When the network is re-applied to itself, the model automatically normalizes the changes in probability. This then produces the exact same output on itself. A method to fix this may be to modify the training data to include floats as a solution, however the first problem of converging to 0 would still be present.

The second method is the greedy method, where the cell with the greatest change in probability is flipped, and used as input for iteration. This method completely disregards the scoring network and relies solely on the probability network, which could cause erratic behaviour. A major problem of greedy search is getting in a loop which is inescapable. For example, a loop could be created whereby the greatest change in cell value is a particular cell whether it is on or off, causing the tree search to continually flip the cell, preventing it from converging towards a solution. 

\section{Hyperparameter tuning}

\subsection{Model Parameters to Tune}

Parameters for the neural networks were typical parameters in any convolutional training problem. The following parameters were tuned, either manually or via early stoppage, of both the probability change network and scoring network training programs:

\begin{itemize}
    \item Learning rate
    \item Number of epochs
    \item Dataset size
\end{itemize}

The major difficulty with the probability change network to find new spaceships is avoiding overfitting. Overfitting in deep learning is when a network fits the training data very well, but does not perform as expected in a general scenario. This leads to program to only find existing ships, and discourages it from finding new ones. To mitigate this effect in the two different networks, early stopping was used. With this method, around 10 epochs were found to be optimal in training the neural networks. The learning rate was set quite low, 0,0005, as the model is very sensitive and therefore does not respond well to larger learning rate values. This value was found after some manual testing, as training took too long to optimally fine tune the learning rate. The size of the dataset is also an important factor, as a dataset which is too large may still overfit, even whilst controlling the number of epochs. Since all of the solution pairs are based off a small initial number of ships, it stands to reason that too many of said solution pairs will prevent the network from converging to a general point. To mitigate this issue, the network was trained on 20 solution pairs for every number of cells missing, which was found via manual testing, and hardware limitations (as increasing the number by 1 can add up to 50,000 solution pairs, significantly slowing down the training time).

As for the scoring algorithm, it was easier to tune the parameters, as it was comparatively quicker to train than the probability change network. Early stopping was also used for the number of epochs, and learning rate was tuned via an optimizer. The dataset was quite large, but was ultimately the same size as the one used in the probability change network training. A learning rate of 0.001 was found to be most effective. 5 epochs were found to be optimal for early stoppage.

\subsection{Algorithm Parameters to Tune}

There are a lot of parameters to the algorithm, which greatly affects the effectiveness of the search. Here are the notable ones:
 
\begin{itemize}
    \item $max\_depth$ : how deep should the tree go before ending a search iteration
    \item $n\_iterations$ : how many tree searches should be done with re-calibrated input
    \item $n\_considerations$ : the number of nodes that are created for cell removal and cell addition (a maximum of $2 \times n\_considerations$ child nodes are possible)
    \item $n\_tree\_returns$ : the number of grids returned by tree search which had the highest scores
    \item Upper threshold constant value: the constant that is used to determine if a cell should be added to the structure (brought to life)
    \item Lower threshold constant value: the constant used to determine if a cell should be removed from the structure (killed)
\end{itemize} 

\subsection{Tuning the threshold parameters}

The probability change network has two main functions: to reduce the probability of a cell that is unlikely to be in a spaceship, and to increase the probability of a cell likely to be in a spaceship. This was tested by taking the mean increase in values. For cells that are not part of the spaceship (so called "undesirable cells"), the mean probability increase should be negative. For cells we want in the structure as they are part of a spaceship (desirable cells), the score should be positive. For cells which are not present in the structure and are not desired, the score should be close to 0. A similar value should be had for cells already present in the structure which should stay in the structure: there should be little to no change in probability. 

To find this graph, a set of ships were chosen, and incrementally, cells were removed from the ship. At the same time, extra cells were added, a similar method to the deconstruction method used in the data generation for training the neural networks.

\begin{itemize}
    \item Positive score: the mean value in desirable cells (the higher the better)
    \item Negative score: the mean value in undesirable cells (the lower the better)
    \item Intactness score: the mean value of cells in the structure that need to stay in the structure (the higher the better)
    \item Cohesion score: the mean value of cells added to the structure that need be removed (the lower the better)
\end{itemize}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/n_removed_cells_score_probability_analysis.png}
\caption{Mean scores for positive, negative, intactness and cohesion on different ships. On the x axis, the number of removed cells is represented. On the y axis, the average score the network assigned to a group of cells is displayed. Ideally, the "positive" and "intactness" line would be close to 1, and the "negative" and "cohesion" line be close to -1}
\label{fig:subim1}
\end{figure}

As can be seen by the graph in Fig 4.10, the results are mixed. Although the positive value is high, it is quite close to the negative value. Ideally, the negative score line would've shifted far into the negatives, however it is positive in value, meaning that applying the probability change network on itself would, on average, increase the probability of cells which should not be present. The intactness score is also low. In an ideal scenario, the intactness score would be at the very least above 0: cells already part of the ship should not be removed. Finally, the cohesion score is quite good: the value is on average very negative, meaning cells which are not supposed to be present are being removed by the model network. From this graph, we can extract some of the tuning parameters:

\[ upper\_constant = 0.15 \]
\[ lower\_constant = -0.6 \]

However, these threshold values can be improved upon. By making them dynamic, the deeper the search gets, the more the thresholds increase in size. This is done for two reasons: to weed out cells which are irrelevant the closer you get to a ship, and to allow nodes already explored to be re-explored. The "explored" list is only used when there are no candidate cells given a state, so by increasing the threshold values, the number of candidates go down and allow for other paths to be visited. The formula for those computations are as follows:

\[ upper\_bound = upper\_constant + (\frac{current\_iteration}{max\_depth} \times  0.1)\]
\[ lower\_bound = lower\_constant - (\frac{current\_iteration}{max\_depth} \times  0.1) \]

Where $current\_iteration$ is the $i^{th}$ iteration in the tree search sequence. These equations were found as optimal after testing. These values allow only a max upper bound of $u \leq 0.25$ and a minimum lower bound of $l \geq -0.7$, which prevents the bounds from being unreachable by candidate cells. Due to this, the tree search can still find new candidates, however will encourage the search to go back to previous results. more often at the end of the search. The equations were found to be optimal after manual tuning, but also from analysing the maximum vales outputted by probability change network; ensuring the thresholds cross them eventually.

Applying the network to see the extrapolated cell counts after the thresholds are set is equally important in determining the efficiency of the model inside the search algorithm. In Fig 4.11, the number of cells that have been added to the network which are not part of the spaceship, and the number of cells added which are part of the ship are shown. As can be seen from the graph, the number of cells missing is quite low, with about half of the initial cells missing having been recovered. However, the number of extra cells is quite significant. These extra cell counts can be explained in Fig 4.12. This graph shows the average score of the extra cells: they are very positive, to the point where the probability surpasses the threshold. On the flip side, the missing cells have a very negative value. This leads to cell probabilities being in the wrong threshold limits, and the wrong cells being flipped. The only solution to this is to re-train the probability change network into giving more accurate predictions on cell probability changes.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/cells_removed_n_cells_extra_missing_probability_analysis.png}
\caption{Number of removed cells compared to number of cells missing/extra after extrapolating a new grid using pure network outputs and the set threshold values. In an ideal scenario, both lines would be as close to 0 as possible.}
\label{fig:subim1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/cells_added_n_cells_extra_missing_probability_score_analysis.png}
\caption{Number of removed cells compared to the average score of cells missing/extra. The missing cells are negative (we want them to be as positive as possible), and the extra cells are high in probability (we want them to be as negative as possible)}
\label{fig:subim1}
\end{figure}

\subsection{Tuning the other parameters}

The number of iterations, number of cells considered, and the max depth are also important factors. If the number of cells considered is higher, then there will be a greater number of branches in any given node, which makes the program slower. However, there is a greater chance of finding a branch with a higher score, which could increase the performance of the search. Similarly, a higher max depth value will lead to a more thorough search of a start configuration, but it will make the program slow. Another consideration to choosing the max depth is the initial state. If the user is looking for new ships, then they will only start with a few cells in the initial configuration. This means a high max depth is needed to fill in the empty cells. However, if repairing a ship, a lower max depth may be beneficial in order not to skew too far from the ship structure, and make the search more efficient. The number of iterations has less of a trade off. The more iterations there are, the higher the likelihood of finding the ship. However, to keep the algorithm short, a small testing value was used. Furthermore, max\_depth is made as a function of the amount of iterations there has been, which is a form of iterative deepening. Turning the max\_depth into a function prevents the algorithm from getting into a loop, as a situation may arise where the output of tree search aggregates to be the previous input to that search. The max\_depth modifier is increased as the number of iteration increases. After manual tuning of both equations and values, the following parameters were set:

\[ n\_considerations = 3\]
\[ max\_depth\_constant = 30\]
\[ max\_depth = max\_depth\_constant + (1 + (0.1 * iteration\_count))\]
\[ n\_iterations = 3\]

Where $iteration\_count$ is the number of iterations that have passed at the moment tree search is called. It must be reminded that these values can be modified according to what type of search is needed. For a more intensive search, a higher number of iterations can be set. If the search is starting with a grid with few cells, the max\_depth should also be increased. Finally, if more computing power is available, it is worth considering increasing the $n\_considerations$ variable.

\section{Tools Created and Used}

\subsection{RLE Encoding}

Since storing a GoL matrix is quite expensive, a compression method is used to store structures. It is a type of run length encoding (RLE), which denotes the cells that are alive. RLE encoding is used extensively when generating training data for the different networks. The encoding takes place over two lines, with one containing the size of the structure, and the next one being the actual token encoding method. The first line is represented by: $x = n, y = m $ such that the structure is of size $n \times m$, width and height respectively.

The tokens used in this encoding are as follows:

\begin{itemize}
    \item $b$ : dead cell
    \item $o$ : alive cell
    \item $\$$ : end of line
\end{itemize}

Every token is represented by a number before the token. If there are $n$ alive cells in a row, it is represented as $n$o. If a cell does not appear consecutively, there is no number associated with that token. For example, an interweaving of dead and alive cells on a single line would be represented as $obobobob$ and so on. After the last alive cell, the dead cells are not encoded into the RLE code, it is assumed automatically. If there are $n$ empty lines in a row, then the empty lines are denoted as $n\$$. An example RLE is of the glider:

\[ x=3,y=3 \]
\[ bo\$2o\$obo! \]

The RLE values for spaceships used in the ship search were stored in a text file which needed to be extracted and processed when training, validating, or testing data. Using RLE encoding not only made storing ships easy, but comparing them is also very efficient (two RLE codes would match).

\subsection{The Game of Life}

To execute some parts of the program, such as the spaceship check method, a GoL implementation was needed. There are some existing tools in python to run the GoL, namely "Golly", which is used in some python search algorithms like "gfind". The use of Golly was considered in the project, however its lack of versatility, poor documentation, and difficulty in adding test code led to the decision of creating an independent GoL tool using numpy. This allowed great leverage of the code, and made different step-by-step analyses easier to manage. The cells are represented in an $n \times m$ numpy matrix, and every time step a neighbour matrix is applied to find the number of neighbours of an individual cell. With this information, the rules of the GoL can be applied, and a new matrix representing the next time step is produced. 

Inside of this GoL implementation, several sub-tools were produced, such as:
\begin{itemize}
    \item A function to return the next time step, or the state after $t$ time steps 
    \item Representation of the current board using Pygame / matplotlib
    \item Ship data calculator: extracts the speed, size, and general properties of a structure
    \item Structure manipulations: normalizing a structure to fit the RLE encoding, extracting a structure from noise, putting a structure into a sandbox (empty grid) environment
\end{itemize}

These methods were used in a wide variety of ways, from training the networks, to analytics. Further modifications of the GoL code allowed structure data (such as average neighbours, average number of cells over time, changes in cell values) to be extracted, which could not be done with Golly. 

\subsection{Determining if a structure is a ship}

The $checkSpaceship()$ function to find spaceships was used in a relatively straightforward manner. First, a maximum period search time is defined, $p$. This value will be the maximum period a found spaceship can have, which is used to prevent a structure from evolving forever. The idea is to take the structure, place it in an expanded empty grid, and evolve it until it has reached its initial state. The main drawback of this method is that ships which have a period above $p$ will not be detected. Furthermore, this approach is inherently slow: with $p$ iterations and $n$ spaceships needed to be checked, it is quite heavy on the search. In addition, larger cell structures take more time to check, as they need a larger grid. This value is also variable. The width and height of the search affects the space needed for ship detection. A $100 \times 100$ search grid needs a padding of 150 cells in each direction in order to properly assert that a structure is indeed a ship. Therefore, a function to determine the search size needs to be formulated, which can depend on the spaceship, given some expand a great deal before contracting into their original shape again. In this search algorithm, a padding size of $padding = 150$ was used as a default. However, it is recommended that the padding size be of the form $padding = max(w, h) \times 1.5$ where $w$ and $h$ are width and height respectively.

Not only was a boolean value of whether a structure is a ship is returned, but also its speed and direction. Measuring the speed and direction of the ships is also a relatively simple task, as the period $p$ will be the number of iterations it took to reach a distance $d$ from the original position. Speed is calculated for both the horizontal and vertical axes, giving a speed indication as described in section 2.1.4. An optional check is carried out by this method to verify if the ship is in its own database (if the structure is not in said database, then it is newly discovered ship).

\subsection{Analytical Tools}

The tools build to test the different networks and the search algorithm were extensive. As seen previously in figures 4.10, 4.11 and 4.12, a lot of analysis was done on different cell removal values. However, more analyses were done on max\_depth values, and iteration counts, which were used to generally test the algorithm and figure out some useful values. Analytical tools worked quite simply by iterating over several lists of possible parameter values, and recording them in a pandas table.  Data processing using pandas' aggregator function was used to collect relevant data, and matplotlib was then used to display these results in a useful fashion. 

Three main tools were used to test the algorithm: the probability change network tests, the scoring network tests, and the search algorithm tests. These were implemented as 3 separate functions, which ran when a new model was trained. A grid CV search method was used in each of these methods to get optimal values. Every test value is iterated over to find the best, and produce graphs to display the efficiency of the algorithm. The probability change network relied on the scoring graph such as the one in Fig 4.10, and was the most efficient way to test the efficacy of the network. Testing the scoring network was quite easy, as different structures were tried to correlate the score. This made it extremely quick, and easier to fine-tune compared to the probability change network and the search algorithm. As for algorithm itself, tests had to be run on a smaller subset due to the time taken for a single execution. All the results of tree search were returned, and an average is taken over those results. An important metric is the probability of reconstruction, which involved running the algorithm on a set of cells with missing ships. The deconstruction tool helped in creating ships with this deconstruction: by removing a number of cells $n$ and adding a few random ones, just like in $ratioDeconstruct$ which was used in the data augmentation.


\subsection{Summary}

In this chapter, we looked at the techniques and technologies we used to develop the search method, which included a whole host of python programs like numpy, pandas, matplotlib, and general work methods used to plan development. This was then followed by previous attempts to solve the problem, such as the ship probability method and stochastic ship cell probability, along with their shortcomings. For example, ship probability not taking into account the determinism of the problem, and the convergence issues of a stochastic search. In the challenges section, we go over the major difficulties of the problem, such as the complexity of the problem, slow convergence of networks, large amounts of data, and limited previous work done on the subject. The probability search section went into detail about the two networks used (the probability change network and the scoring function), and how they are used in the tree search algorithm. This algorithm was described in detail, describing a type of A* search method, along with the iteration over the the tree search being beneficial to reaching a solution. In the tuning section, we go over the important threshold values to deciding if a cell should be set or not given the output of the probability change network, and how we fine tuned it. Equations are given as to how to make these values dynamic depending on the current iteration or depth of the search. Finally, the tools section goes over important scripts that were used to build the program, as well as analyse it, such as RLE readers, GoL implementations, and analytical tooling.


%==================================================================================================================================
\chapter{Evaluation} 

\section{Aims}

The main question to answer in this paper: does using neural networks in a tree search of spaceships work in practice? Success in this measure would mean at the very least converging to a known solution which has not been seen by either neural networks. This would entail removing cells from a spaceship which has not been trained on, and reconstructing the original ship through the search. Ideally, it should be done in a way that beats random selection of cells. However, it is also not a binary metric: the performance is to be measured on a range of missing/extra cells. If the number of missing cells from the ship is high, and the algorithm can still reconstruct the original ship, then it is a sign it is performing well. An even better metric would be to find a spaceship that has not been discovered as of yet.

Another question that would be greatly beneficial to answer would be that of the main assumption: is there a general pattern to spaceships that can be found using a neural network? Success in this domain is harder to define. If a the probability change network is consistently scoring the next cells to be placed correctly, then it would be a measure of success. If the scoring network is correlating close to the MSE (Mean Squared Error) of a spaceships with cells missing, then this also may prove that the network has learned a general pattern to said ships.

\section{Methodology}

The experiments were run via a singular analytics script, which went through every metric devised. Testing values were stored in a table of results aided by pandas, and then graphed with matplotlib. The analytics program was ran every time a change to the network was made, or to manually tune parameters. Furthermore, the script is compartmentalized into metrics for the two different networks and the algorithm as a whole, allowing tuning using a grid search for different parts of the program. 

To keep the experiments on different values fair, the following control variables were set to be constant:
\begin{itemize}
    \item max\_n\_considerations: number of branch nodes for any given node, set to 3
    \item max\_depth: max depth of tree search, set to 30.
    \item n\_iterations: number of iterations over tree search, set to 3.
    \item n\_tree\_returns: number of best grids found by tree search, set to 5.
\end{itemize}

Said values were found by manual trial and error of the algorithm. This was set manually as searching for the optimal values was impossible given the hardware available. Another aspect to note is the number of iterations, which was set to 3 for similar reasons. Although the number of iterations being set to a higher value would almost guarantee better results, the algorithm is costly and restrictions needed to be set due to the time limit of this project.

The following independent variables were used as testing metrics:
\begin{itemize}
    \item Number of distinct ships tested on: 50
    \item Spaceship types: seen or unseen (spaceships that have been trained on, and spaceships that are used for testing)
    \item Number of cells removed: from 0 cells removed to 50.
\end{itemize}

% IS THIS CORRECT?
These were used to standardize the results for any given testing metrics. Fifty spaceships is enough to get a reliable trend on the data, allowing for smooth curves and trends to be found. To ensure the split between training and testing data, the dataset of non-augmented ships was split before any network training was done. Randomly splitting the dataset allowed for smaller as well as larger spaceships be present in both datasets, removing bias. It is important to note the reason for splitting the original dataset and not the augmented one: the objective is to find new ships, so exposing the networks to training data that has the same base pattern as testing ships may affect the result. A noticeable variable is the number of cells removed. 50 cells is enough to completely delete a spaceship from the grid, and replace all of the cells with random ones. This is intentional, as it tests the ability of the search to work from scratch.

Dependent variables used for measuring the performance of the two different neural networks and the search algorithm as a whole:
\begin{itemize}
    \item The average score (probability increase/decrease) in a given group of cells
    \item The number of extra/missing cells in a spaceship after applying the threshold values 
    \item The average score of extra/missing cells after applying threshold values
    \item The MSE (Mean Squared Error) between a resulting grid and the target spaceship 
    \item The number of spaceships that were found for any amount of missing cells
\end{itemize}

These metrics give a good idea of performance as a whole. The scoring network, for example, will only be measured via the MSE metric, since it is trying to correlate a score to said metric. However, the search algorithm can be measured by the number of spaceships found, average score of extra/missing cells, and the number of extra/missing cells. Other values were experimented with; for example the average MSE of algorithm results compared to the original ship deconstructed. These performance results proved less indicative than those listed above, and therefore were not included in the final set of results.

\section{Results}

\subsection{Probability Network Performance}

Although the probability network worked decently with training data, it had severe limitations when used on unseen test data. In Fig 4.10, scores using training data are shown. There are clear tends: a high value for desired cells, and undesirable cells have a lower score. However, on untrained data (Fig 5.1), the results were less positive. The network remains good at removing "undesirable" cells which have been added by the search algorithm, however the "desirable" cell scores have dropped drastically, as well as the intactness score. These trends indicate that the probability network has generalized poorly. Without these high positive values, it is very hard for the network to correctly predict which cells are the best candidates, making mistakes more likely. As seen later in the evaluation of the entire algorithm, the probability network greatly affects the performance of the search in a negative way. In Fig 5.2, further evidence shows the scores of missing and extra cells from the ship. Since the score for extra cells score is so high, it is impossible to create threshold values that exclude them whilst keeping actual missing cells. This is also true for the missing cells scores: they are below threshold values for removal, so there is no way to differentiate them from actual extra cells. Threshold values were re-tuned multiple times to try and find an optimum, but ultimately there is too much noise and no clear split between the cells. From these results, it is resoundingly clear that the probability change network has not found a general pattern to spaceships. Although the cohesion score seems encouraging, the network is inherently negative, meaning it is good at removing some cells which have been added that should not be there. However, the undesirable cells are still high in value. This implies that cells not supposed to be there (extra cells) will still appear.

% do i include missing/extra cell scores?

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{dissertation/images/graphs/n_removed_cells_score_probability_analysis_test.png}
\caption{The probability scores for untrained data. It is mostly the same, however the positive scores are even lower on the graph. This is bad, although by re-tuning the threshold it is possible to increase the efficiency of the search on untrained data.}
\label{fig:subim1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{dissertation/images/graphs/cells_added_n_cells_extra_missing_probability_score_analysis_untrained.png}
\caption{Average scores of missing/extra cells when ran through the probability change network using test data. Ideally, the missing cells line should be close to $y=1$, and the extra cells score should be close to $y=-1$.}
\label{fig:subim1}
\end{figure}


\subsection{Scoring Network Performance}

The entire objective of the scoring network is to best approximate the MSE function from a structure to a spaceship. The output of the scoring function is an increasing value as it gets closer to the ship. However, the actual MSE approaches 0 as the structure gets closer to the ship. To best represent correlation between the two, the axis in this example has been flipped on $y = 0.08$. Measuring the effectiveness of the scoring network was easy: just remove cells from the ship and test to see the network output.
% maybe add the original scoring function here

 The results on the test dataset yielded very good scores. In Fig 5.3, the actual and predicted MSE scores correlate on the training data. More interestingly, in Fig 5.4, there is a clear correlation between the true MSE and the predicted MSE on the test data. This could potentially imply that the main assumption of  a general structure being present in spaceships is true. Furthermore, a direct correlation is not exactly necessary. Since the objective of the scoring function is to direct the search to a solution, the main feature needed is a downward correlation between distance from structure and a potential ship. However, it remains to be seen what exactly causes this MSE to work as well as it does. It could be due to a particular density of alive cells in a certain area being more likely to be a spaceship, and not the actual form of the structure itself. To test this, we used the deconstruction method to add random cells in the structure where dead cells are supposed to be, keeping the density at a similar level. As can be seen in Fig 5.3, this correlation was still present given these extra cells, indicating that the network may be functional.

 % should I test this scoring network by giving it all cells as an option and see if it picks correct one?
 

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/cells_missing_to_score_trained.png}
\caption{Number of removed cells to predicted score for trained ships. Both lines trend downwards, which means the MSE decreases as the ship approaches completion, implying a general pattern has been found.}
\label{fig:subim1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/cells_missing_to_score_test.png}
\caption{Number of removed cells to score for untrained ships. The predicted score and actual score correlate well.}
\label{fig:subim1}
\end{figure}

\subsection{Search Performance}

% TALK ABOUT TESTING ON AN EMPTY / VERY SPARSELY POPULATED GRID TO CHECK THE PERFORMANCE

The outputs of the search could be manipulated in several ways to produce evaluation metrics. Most of them also revolve around the idea of "missing" and "extra" cells after the program has finished executing. The metrics are taken from the top $k$ boards at every iteration which are returned after tree search, and are averaged by number of missing cells. The MSE of the structure is also calculated, along with the reconstruction chance, which is calculated by taking the number of times a spaceship was found over the total amount of times tree search was run.

% SHOULD I INCLUDE THE PARAMETER TUNING STUFF?

\begin{itemize}
    \item The number of cells missing: number of desirable cells not part of the structure
    \item The number of cells extra: number of undesirable cells
    \item The MSE score from to the target spaceship
    \item The chance of reconstruction given number of cells missing from original ship
\end{itemize}

However to truly test if the algorithm is performing well, the best metric is the chance of reconstruction given a number of cells missing. Results from running the algorithm on a test dataset are disappointing. The probability of ship reconstruction is virtually 0 for any ship that has not originally been trained on, as can be seen in Fig 5.5.

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/probability_of_reconstruction_against_damage_testin_only.png}
\caption{Number of removed cells to probability of reconstruction for untrained ships (ships that were not used in training the networks)}
\label{fig:subim1}
\end{figure}

A failure in the probability change algorithm is the most probable contender for the poor results, which are most likely due to overfitting of the network. Being that there are so few ships to begin with, and the network takes a long time to converge, this is somewhat unsurprising. However, reconstruction probability from trained ships is higher. Although not useful to finding new ships, this does point to the possibility that the search algorithm may work if a better trained network is used. The results of reconstruction are outlined in Fig 5.6, which shows that the probability of reconstruction on trained data is quite high. Performance can be found by area under the curve: the higher it is, the better. It can be seen that even with the training data, the algorithm has a lot of room for improvement. Another potential issue is the tree search itself. Given the issue of computing power, optimal parameters were not thoroughly tested for the number of considerations, or for the number of best states returned by the tree search. These are parameters that could greatly change the outcome of the search algorithm. To determine the optimal parameters, more grid search would have to be performed, but it was not feasible given the hardware used in this paper. 

In Fig 5.7, the average number of missing and extra cells in the best nodes found during the search is encouraging. However, it is important to note that these results are based on the training data. The number of extra cells being so low makes sense: the algorithm is quite negative in the way it scores cells, especially undesirable ones. This keeps the algorithm focused towards only beneficial cells to the ship. On average, the number of cells missing is $0.9$ times the number of cells removed, meaning that there are less missing cells than started with. 

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/probability_of_reconstruction_against_damage_trained.png}
\caption{Number of removed cells to probability of reconstruction for trained ships (ships that were used in training the networks)}
\label{fig:subim1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/number_of_cells_n_cells_removed_trained.png}
\caption{Average of the best scoring nodes from the search algorithm on trained data. The average number of missing cells and extra cells are recorded. On average, there are 2 missing cells less than started with.}
\label{fig:subim1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{dissertation/images/graphs/cells_added_n_cells_extra_missing_probability_analysis_untrained.png}
\caption{Average of the best scoring nodes from the search algorithm on untrained data. The number of missing cells is attributed to being an average of random cells being removed.}
\label{fig:subim1}
\end{figure}

\subsection{Comparing the Search Algorithm with Existing Ones}

It is quite hard to compare the performance of this search algorithm with others, given how different they are. Since the neural network approach uses base cells, and works off a known pattern for it to work, it is difficult to find metrics which could best represent it as a comparison to other algorithms. In addition, there does not exist widely-accepted comparison metrics in the community, as it is usually based on vague elapsed time measurements to find a certain ship. One of those ships is "Sir Robin", an elementary knightship (a ship which moves in an oblique direction) and has a size of $31 \times 79$. In the forum page of the release of "ikpx2", the author mentions that the ship "Sir Robin" was found after 52 minutes running on 8 threads \citep{ikpx}. As a rudimentary test, the search algorithm was run for 7 hours with $n\_iterations = 30$ and $max\_depth\_constant = 100$ on an initial grid size equal to "Sir Robin"s', and with 5 starting cells that occur on that ship, however the ship was not found. Although not a robust test, this does show that the search is potentially less performant than "ikpx2".

\section{Discussion}

Based the results and observations, it can be inferred that while the search algorithm fell short of expectations, using neural networks can help identifying spaceships to a certain degree. There are several issues with the algorithm, the main one being the probability change network, one of the centerpieces of the search. While the probability of reconstruction on training data had success, pointing to the possibility of a potential generalization given a different network, it was not as successful in other areas. As seen in section 5.3.1, the network performs inadequately on unseen test data, which is likely to be due to a failure to find to a general solution. This could be caused solely by overfitting as there was little spaceship data to train the network on. Nevertheless, without extensive training of the network on the data, it was unable to converge, implying that no general solution exists. Furthermore, due to the search problem being inherently deterministic, a convolution may not be the best network choice, as it is prone to noise. Further testing is required to ascertain the best network configuration, and the optimal parameters.

On the other hand, the scoring network had quite promising results. Not only does it model the MSE (Mean Squared Error) of the training data well, but it models the test data in the same way. If the scoring network is able to converge onto a seemingly general solution, this could imply the existence of a fundamental pattern to spaceships identifiable by neural networks. Although the scoring network could have generalized, it could also be that another feature, such as density, or location of cells on the board, could be the cause of this correlation. The fact that the network correlated well does not prove the existence of a general pattern for spaceships, but it is a strong implication. A future way to test this correlation would be to give a correct cell as an option at every iteration of the tree search. If the heuristic function is consistently higher for the correct node, and selects it, then it could be proof of the network has found a fundamental pattern to spaceships. 

Given all these issues, it would be easy to brush off this search algorithm as a failure. But there is still use to it. For example, the network converges quicker than logical algorithms in grids above a size of $20 \times 20$. In a typical logical search algorithm, it would take a lot of time for the search to reach higher levels, such as $100 \times 100$ grids. Using the probability network, it is possible to quickly reach a set of cells which might contain a spaceship, even though a final working structure is not found. If combined with a typical logical search, it may be possible to improve the algorithm into finding correct ships which are currently too large to do a logical search with.

\section{Summary}

The main objective of being able to find new spaceships was not reached. The search algorithm found very few spaceships from the testing data, and only those which are missing 2 cells. Although it can be said that the search worked with trained data, as the reconstruction rates were much higher. This is better than a random search, but is still not enough proof to ascertain that the algorithm is working as intended. Furthermore, after running the network on some starter configurations, no new spaceships were found. However, there are some promising findings. The scoring network worked much better than anticipated, correlating almost perfectly with the actual mean squared error of ships in the testing dataset. This does not prove the the assumption that spaceships have a general pattern, however it does pave the way for future progress. It is still an open question whether or not the scoring network has properly learned to score a potential spaceship, or if it has learned another feature, such as the density in the area where a spaceship should be. To determine this, more neural networks would need to be trained and tested.


%==================================================================================================================================

\chapter{Conclusion}    

\section{Conclusion}

The objective of the paper was to explore deep learning as a way to accelerate the search for spaceships in the Game of Life (GoL). Spaceships are oscillating structures which move in a set direction, and are difficult to find due to their deterministic nature. Few different ships have been found, and although there are an infinite number of them, they are exceedingly rare in the large search space. The search was done by representing the problem as a tree graph, and choosing a path using A* aided by the outputs of neural networks. Iterative deepening is used on the A* to guide the algorithm, and prevent the tree search from being too focused on a single sub-tree.

The two neural networks used were: a probability change network, which finds the potential branches to any given node, and a scoring network, which is used as a heuristic function. The heuristic function is used to decide the next node to be picked from those given by the probability change network. To train both networks, engineered and elementary spaceships below $100 \times 100$ in size were used. This gave a small dataset of 31 ships. Data augmentation was used to increase the number of ships to train on, leading to a dataset size of around 900. A training dataset is then created using a deconstruction method, which entails removing cells from a ship and adding random ones elsewhere. A training pair can then be made based off the deconstructed ship and the original ship.

The actual search itself works in two parts: tree search, and iterative deepening over the tree search. The tree search itself is an A* search using said networks and nodes. Candidate nodes are found from the output of the probability change network. Cells which have the highest probability of change are selected as candidates, if they are above a certain threshold. The next node is selected by comparing the heuristic scores of the candidate nodes, with the highest one being chosen. If the chosen node has a better score than the current best-scoring node, it is added to a list of best nodes. A subset of the list of best nodes is returned at the end of the search. Iterative deepening runs over tree search several times, increasing the max depth and using the outputs of the previous tree search iteration to create a new input for the next tree search iteration. This new input is found by aggregating the outputs of tree search in a way that only keeps cells in common, and is done to make sure the "core" elements of the ship are retained.


The data augmentation, from expanding one ship into many, to using a deconstruction method to create many solution datasets, has many advantages and disadvantages. For starters, it can easily create a large dataset out of very few ships. This is good, as data on the GoL is sparse in general, therefore being able to expand the dataset in this manner is a great improvement. However, there remain issues with this approach. Since the initial dataset is so small, it remains to be seen if a pattern to spaceships can be derived from only those base spaceships. Deriving all the augmented data from this initial dataset leads to severe overfitting of the initial data, seriously harming the performance of the network on unseen data.

The probability change network was designed in a convolutional manner, as the game of life has locality inherently present in its system. These convolutions used $3 \times 3$ and $5 \times 5$ convolutions, which were chosen after tying out a set of different values. Although the network proved it could predict cells on trained data, it failed to do so more generally. Regardless of this, it shows that an approach involving locality is effective compared to a fully connected network, which makes sense. It may be that more/less convolutions could bring about better results, however this is yet to be tested. A different approach to the convolutions, for example a UNet, or a similar denoiser network, may be more effective. Furthermore, the opposite operation could be done: start with a grid of cells all alive, and remove those which are not useful to a ship.

The results were mixed. Although a neural network was seemingly trained to predict the MSE (Mean Squared Error) from a structure to a ship, the probability change network was inadequate in finding the correct cells which should explored. Testing on the training dataset led to the algorithm finding ships, however there were poor results on the test dataset, most likely due to overfitting of said probability change network. Nevertheless, the results are somewhat promising, and pave the way for more research to be done in the future. This paper was unable to prove or disprove a general pattern to spaceships detectable to neural networks, but it did pose some interesting questions and results. It is also possible that a general pattern for all spaceships cannot be found, but there may be patterns for certain categories of ships going at a certain speed for example. Training networks would need to only focus on those sub-groups.

\section{Future Work}

In recent years, denoiser networks have been incredibly effective in creating sharp images using context \citep{Zamir_2022_CVPR}. If these networks could be trained in a way that could find spaceships; and the general spaceship pattern hypothesis is true; then there is a lot of potential. Furthermore, adding a logic based spaceship search after the output of the neural network search may yield interesting results. Since it was seen that the network can quickly find large structures, a logic search based off this output may find new ships. However, this still depends on the general spaceship hypothesis, and a new network may need to be trained to specifically target this task.

As a final note, using a network to predict the shape of a spaceship may not be the only way to solve this problem. Another interesting approach would be to train a network, such as the scoring network, to find the "utility" of a pattern. A genetic algorithm could then be evolved to maximize this utility function, which could be tuned to find spaceships with a certain property (size, speed, period). This method may have more base data to work with since a linear scoring method could be created, similar to the scoring network in this paper, which performed quite well. 

%==================================================================================================================================
%   BIBLIOGRAPHY   

% The bibliography style is abbrvnat
% The bibliography always appears last, after the appendices.

\bibliographystyle{abbrvnat}

\bibliography{l4proj}

\end{document}
